---
title: "Exploratory Analysis on SwiftKey Dataset"
author: "kuriboh"
date: "10/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(cache=TRUE)
```

## Normalizes text in the dataset  
The first step I want to perform is normalizing words in the datasets:  
* Transform words to lowercase  
* Remove all punctuation  
* Words are separated by only spaces  
```{r, eval=FALSE}
normalize_paragraph <- function(paragraph) {
    remove_non_alphabetical <- function(sentence) {
        sentence <- strsplit(sentence, '')[[1]]
        sentence <- sentence[sentence >= 'a' & sentence <= 'z' | sentence == ' ']
        paste(sentence, collapse='')
    }
    n_sentences <- length(paragraph)
    answer <- list()
    for (i in 1:n_sentences) {
        paragraph[i] <- as.character(paragraph[i])
        paragraph[i] <- tolower(paragraph[i])
        paragraph[i] <- remove_non_alphabetical(paragraph[i])
        words <- strsplit(paragraph[i], ' ')[[1]]
        answer[[i]] <- words[nchar(words) > 0]
    }
    answer
}
# my_paragraph <- c('A7, bU*  c', 'A78u. o  O')
# normalize_paragraph(my_paragraph)
# head(normalize_paragraph(news_data[1:10000]))
news_data <- normalize_paragraph(news_data)
blogs_data <- normalize_paragraph(blogs_data)
twitter_data <- normalize_paragraph(twitter_data)
```
  
## One more optional step, I consider text from those three datasets has the same role. Thus I will merge those dataset into one  
```{r, eval=FALSE}
combined_paragraph <- do.call(c, list(blogs_data, news_data, twitter_data))
rm(blogs_data, news_data, twitter_data)
```
  
## Does exploratory analysis  
* Firstly I'm curious about how many sentences are there and how many words in each sentence are there in average  
```{r}
length(combined_paragraph)
sum(sapply(combined_paragraph, length))
mean(sapply(combined_paragraph, length))
```
  
## Get single words occurences  
```{r, eval=FALSE}
library(hash)
dict <- hash()
increase_count <- function (my_key) {
    if (length(my_key) > 1) {
        separator <- ' '
        my_key <- paste(my_key, collapse=separator)
    }
    if (has.key(my_key, dict)) {
        dict[[my_key]] <- dict[[my_key]] + 1
    } else {
        dict[[my_key]] <- 1
    }
}
for (sentence in combined_paragraph) {
    for (word in sentence) {
        increase_count(word)
    }
}
```
  
```{r}
one_gram_distribution <- unlist(as.list(dict))
one_gram_distribution <- order(one_gram_distribution, decreasing=TRUE)
head(one_gram_distribution)
```
